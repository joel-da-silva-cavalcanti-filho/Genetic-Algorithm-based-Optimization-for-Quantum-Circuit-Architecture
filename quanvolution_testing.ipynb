{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arbres-rouges-noirs/Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis/blob/main/quanvolution_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n",
        "\n",
        "# Configure your Git name and email\n",
        "!git config --global user.name \"arbres-rouges-noirs\"\n",
        "!git config --global user.email \"joel.filho@unesp.br\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rCfB0BBqZIa",
        "outputId": "1f90f676-9f3d-4c84-b4b5-ba78efad1509"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# Input your personal access token (PAT) to authenticate\n",
        "token = getpass(\"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\")\n",
        "\n",
        "# Set GitHub token for authentication\n",
        "os.environ['GITHUB_TOKEN'] = token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4fff_CGqn65",
        "outputId": "d3ff768a-64c3-451e-9a41-42c014850761"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the notebook file (replace 'YourNotebook.ipynb' with your notebook's name)\n",
        "notebook_name = 'quanvolution_testing.ipynb'\n",
        "repo_name = \"Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\"\n",
        "!cp /content/{notebook_name} /content/{repo_name}/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOXyiMfPq-mZ",
        "outputId": "a9fe13dd-ac44-413b-ad57-98be83e17146"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/quanvolution_testing.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://arbres-rouges-noirs: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@github.com/arbres-rouges-noirs/Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO_M5-cZoBB0",
        "outputId": "363ad230-a867-400c-ed1d-47ed5d179f43"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis'...\n",
            "remote: Write access to repository not granted.\n",
            "fatal: unable to access 'https://github.com/arbres-rouges-noirs/Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis.git/': The requested URL returned error: 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install pydicom\n",
        "!pip install medmnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eE-xGUGgnOS",
        "outputId": "5dcb7140-b821-480e-c6c3-e4d7e5b4b7cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-2.1.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.12/dist-packages (from qiskit) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.12/dist-packages (from qiskit) (1.16.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.12/dist-packages (from qiskit) (0.3.8)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.5.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from qiskit) (4.15.0)\n",
            "Downloading qiskit-2.1.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stevedore, rustworkx, qiskit\n",
            "Successfully installed qiskit-2.1.2 rustworkx-0.17.1 stevedore-5.5.0\n",
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-3.0.1\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from medmnist) (11.3.0)\n",
            "Collecting fire (from medmnist)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from medmnist) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from medmnist) (0.23.0+cu126)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->medmnist) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->medmnist) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.13.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->medmnist) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n",
            "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fire, medmnist\n",
            "Successfully installed fire-0.7.1 medmnist-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "brLsmXO9NiD3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from pydicom import Dataset\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from medmnist import BreastMNIST\n",
        "from medmnist import INFO\n",
        "\n",
        "#import pennylane as qml\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsohmX08NiD6",
        "outputId": "fa9416ec-ecec-4d5d-8130-9e3fec28386d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: Tesla T4\n",
            "CUDA: 12.6\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Using: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Using CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRATeYErNiD7",
        "outputId": "f6be9196-b560-461e-9282-cd24be6a57ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 2\n"
          ]
        }
      ],
      "source": [
        "info = INFO['breastmnist']\n",
        "data_flag = 'breastmnist'\n",
        "DataClass = BreastMNIST\n",
        "\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "print(f\"Number of classes:\", n_classes)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5]),\n",
        "    lambda x: x.unsqueeze(0)\n",
        "])\n",
        "\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5]),\n",
        "    lambda x: x.unsqueeze(0)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zippZ0rWNiD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e2c076-ba15-4c9b-ea22-891b9ec93551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560k/560k [00:00<00:00, 612kB/s]\n"
          ]
        }
      ],
      "source": [
        "size = 28\n",
        "\n",
        "data_train = DataClass(split='train', transform=train_transform, download=True, size=size)\n",
        "data_test = DataClass(split='test', transform=eval_transform, download=True, size=size)\n",
        "data_eval = DataClass(split='val', transform=eval_transform, download=True, size=size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7z3Qa95NiD8",
        "outputId": "582bb671-9d35-4259-b7af-c9de4b291763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of images in training dataset: 546\n",
            "Number of images in test dataset: 156\n",
            "Number of images in validation dataset: 78\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "dataloader_train = data.DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
        "dataloader_test = data.DataLoader(dataset=data_test, batch_size=batch_size, shuffle=False)\n",
        "dataloader_eval = data.DataLoader(dataset=data_eval, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"\\nNumber of images in training dataset: {len(data_train)}\")\n",
        "print(f\"Number of images in test dataset: {len(data_test)}\")\n",
        "print(f\"Number of images in validation dataset: {len(data_eval)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HaKJuiR8NiD9"
      },
      "outputs": [],
      "source": [
        "def quanvolution(image, circuit, patch_size, n_qubits):\n",
        "    \"\"\"\n",
        "    Perform quanvolution on the input image using the given quantum circuit.\n",
        "\n",
        "    Args:\n",
        "    - image (ndarray): The input image (2D or 3D with channels).\n",
        "    - circuit (function): The quantum circuit function to extract features.\n",
        "    - patch_size (int): The size of the patches to divide the image into.\n",
        "    - n_qubits (int): Number of qubits in the quantum circuit.\n",
        "\n",
        "    Returns:\n",
        "    - out (ndarray): The output tensor after quanvolution.\n",
        "    \"\"\"\n",
        "    if image.ndim == 2:\n",
        "        image = np.expand_dims(image, axis=-1)\n",
        "\n",
        "    height_patches = image.shape[0] // patch_size\n",
        "    width_patches = image.shape[1] // patch_size\n",
        "\n",
        "    out = np.zeros((height_patches, width_patches, n_qubits))\n",
        "\n",
        "    for j in range(height_patches):\n",
        "        for k in range(width_patches):\n",
        "            patch = []\n",
        "            for i in range(patch_size):\n",
        "                for l in range(patch_size):\n",
        "                    if (j * patch_size + i < image.shape[0]) and (k * patch_size + l < image.shape[1]):\n",
        "                        patch.append(image[j * patch_size + i, k * patch_size + l, 0])\n",
        "                    else:\n",
        "                        patch.append(0)\n",
        "\n",
        "            q_results = circuit(patch)\n",
        "\n",
        "            # Camada de atenção relacionar os patches e multiplicar atencao pelas features !!!\n",
        "\n",
        "            for c in range(n_qubits):\n",
        "                out[j, k, c] = q_results[c]\n",
        "\n",
        "    return out\n",
        "\n",
        "def quanvolution_batch(images, circuit, patch_size, n_qubits):\n",
        "    \"\"\"\n",
        "    Applies quanvolution to a batch of images.\n",
        "\n",
        "    Args:\n",
        "    - images: Input tensor (batch_size, H, W, C).\n",
        "    - circuit: Quantum circuit used for the quanvolution.\n",
        "    - patch_size: Size of the patches used in the quanvolution.\n",
        "    - n_qubits: Number of qubits in the quantum circuit.\n",
        "\n",
        "    Returns:\n",
        "    - Processed tensor after quanvolution.\n",
        "    \"\"\"\n",
        "    batch_size = images.shape[0]\n",
        "    processed = [\n",
        "        quanvolution(images[i].detach().cpu().numpy(), circuit, patch_size, n_qubits)\n",
        "        for i in range(batch_size)\n",
        "    ]\n",
        "\n",
        "    processed = np.array(processed)\n",
        "    return torch.tensor(processed, dtype=torch.float32).to(images.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "c_uzaXuXNiD9",
        "outputId": "72c7d9f0-a54b-4a09-c386-1da3e0f4e989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py:67: UserWarning: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "  warn(str(ex), UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_gpu/_adjoint_jacobian.py:46: UserWarning: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "  warn(str(ex), UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_gpu/_measurements.py:35: UserWarning: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "  warn(str(error_import), UserWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_gpu/_state_vector.py:32: UserWarning: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "  warn(str(ex), UserWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Pre-compiled binaries for lightning.gpu are not available. To manually compile from source, follow the instructions at https://docs.pennylane.ai/projects/lightning/en/stable/dev/installation.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2908293596.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mrand_circuit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefine_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2908293596.py\u001b[0m in \u001b[0;36mdefine_circuit\u001b[0;34m(rand_params)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m \u001b[0mquantum\u001b[0m \u001b[0mcircuit\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'torch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2908293596.py\u001b[0m in \u001b[0;36mget_device\u001b[0;34m(n_qubits)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lightning.gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefine_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane/devices/device_constructor.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# Construct the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin_device_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# Once the device is constructed, we set its custom expansion function if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wires, c_dtype, shots, batch_obs, seed, mpi, mpi_buf_size, use_async)\u001b[0m\n\u001b[1;32m    263\u001b[0m     ):\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CPP_BINARY_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0;34m\"Pre-compiled binaries for lightning.gpu are not available. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;34m\"To manually compile from source, follow the instructions at \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Pre-compiled binaries for lightning.gpu are not available. To manually compile from source, follow the instructions at https://docs.pennylane.ai/projects/lightning/en/stable/dev/installation.html.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\"\"\"\n",
        "n_qubits = 4\n",
        "n_layers = 1\n",
        "\n",
        "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, n_qubits))\n",
        "\n",
        "def get_device(n_qubits):\n",
        "    return qml.device(\"lightning.gpu\", wires=n_qubits)\n",
        "\n",
        "def define_circuit(rand_params):\n",
        "\n",
        "    Define a parametrized quantum circuit with custom layers and RandomLayers.\n",
        "\n",
        "    Args:\n",
        "    - rand_params: Parameters for the circuit layers.\n",
        "\n",
        "    Returns:\n",
        "    - A quantum circuit function (qml.QNode).\n",
        "\n",
        "    dev = get_device(n_qubits)\n",
        "\n",
        "    @qml.qnode(dev, interface='torch')\n",
        "    def circuit(phi):\n",
        "        for j in range(n_qubits):\n",
        "            qml.RY(np.pi * phi[j], wires=j)\n",
        "\n",
        "        qml.templates.layers.RandomLayers(rand_params, list(range(n_qubits)))\n",
        "\n",
        "        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n",
        "\n",
        "    return circuit\n",
        "\n",
        "rand_circuit = define_circuit(rand_params)\n",
        "\n",
        "phi = np.random.uniform(size=n_qubits)\n",
        "\n",
        "result = rand_circuit(phi)\n",
        "\n",
        "expanded_circuit = rand_circuit.qtape.expand()\n",
        "print(expanded_circuit.draw())\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from math import pi\n",
        "from qiskit.circuit.library import MCXGate\n",
        "\n",
        "def circuit_test():\n",
        "  qc = QuantumCircuit(4)\n",
        "  qc.ry(pi, [0,1,2,3])\n",
        "  qc.ry(pi, 1)\n",
        "  qc.rx(pi,2)\n",
        "  qc.cx(1,3)\n",
        "  qc.rz(pi, 2)\n",
        "  qc.rx(pi, 2)\n",
        "  return qc\n"
      ],
      "metadata": {
        "id": "Alzq5VUFgpxi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H7jMgu2lNiD-"
      },
      "outputs": [],
      "source": [
        "class QuanvolutionModel(nn.Module):\n",
        "    def __init__(self, output_size = (56, 56), patch_size = 4, n_qubits = 4, num_classes = 2):\n",
        "        \"\"\"\n",
        "        Defines the CNN with quanvolution.\n",
        "\n",
        "        Args:\n",
        "        - rand_params: Parameters of the quantum circuit.\n",
        "        - output_size: Output size after quanvolution.\n",
        "        - n_qubits: Number of qubits in the quantum circuit.\n",
        "        - num_classes: Number of classes for classification.\n",
        "        \"\"\"\n",
        "        super(QuanvolutionModel, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.patch_size = patch_size\n",
        "        self.n_qubits = n_qubits\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.circuit = circuit_test()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(output_size[0] * output_size[1] * n_qubits, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Passes the data through the network.\n",
        "\n",
        "        Args:\n",
        "        - x: Input tensor (batch_size, C, H, W).\n",
        "\n",
        "        Returns:\n",
        "        - Logarithmic probabilities of the classes (batch_size, num_classes).\n",
        "        \"\"\"\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = quanvolution_batch(x, self.circuit, self.patch_size, self.n_qubits)\n",
        "        x = torch.relu(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aPUYEk5rNiD_"
      },
      "outputs": [],
      "source": [
        "model = QuanvolutionModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "epochs = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dRHdOc-UNiEB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "0837f8e1-d168-4ccc-9fec-039248f74aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/1\n",
            "\n",
            "[Training]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Batches: 0/18\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'QuantumCircuit' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1101073946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1412490153.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \"\"\"\n\u001b[1;32m     33\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquanvolution_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1143916472.py\u001b[0m in \u001b[0;36mquanvolution_batch\u001b[0;34m(images, circuit, patch_size, n_qubits)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     processed = [\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mquanvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_qubits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     ]\n",
            "\u001b[0;32m/tmp/ipython-input-1143916472.py\u001b[0m in \u001b[0;36mquanvolution\u001b[0;34m(image, circuit, patch_size, n_qubits)\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mq_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Camada de atenção relacionar os patches e multiplicar atencao pelas features !!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'QuantumCircuit' object is not callable"
          ]
        }
      ],
      "source": [
        "last_model_path = \"/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/224x224/1/last_model.pth\"\n",
        "checkpoint_frequency = 2\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "\n",
        "train_losses = []\n",
        "\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_precisions = []\n",
        "val_recalls = []\n",
        "val_f1_scores = []\n",
        "val_aucs = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    print(\"\\n[Training]\")\n",
        "    for batch_idx, (images, labels) in enumerate(tqdm(dataloader_train, desc=\"Training Batches\", bar_format=\"{desc}: {n}/{total}\")):\n",
        "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_accuracy = accuracy_score(\n",
        "            labels.cpu().numpy(), output.argmax(dim=1).cpu().numpy()\n",
        "        )\n",
        "\n",
        "        print(f\"Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.3f}\")\n",
        "\n",
        "    epoch_train_loss = total_loss / len(dataloader_train)\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    print(f\"Epoch {epoch + 1} Training Loss: {epoch_train_loss:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_labels, val_predictions = [], []\n",
        "\n",
        "    print(\"\\n[Validation]\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(tqdm(dataloader_eval, desc=\"Validation Batches\", bar_format=\"{desc}: {n}/{total}\")):\n",
        "            images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
        "            output = model(images)\n",
        "            loss = criterion(output, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            val_labels.append(labels)\n",
        "            val_predictions.append(output)\n",
        "\n",
        "            batch_accuracy = accuracy_score(\n",
        "                labels.cpu().numpy(), output.argmax(dim=1).cpu().numpy()\n",
        "            )\n",
        "            print(f\"Loss: {loss.item():.4f}, Accuracy: {batch_accuracy:.3f}\")\n",
        "\n",
        "    epoch_val_loss = val_loss / len(dataloader_eval)\n",
        "    val_losses.append(epoch_val_loss)\n",
        "    val_labels = torch.cat(val_labels)\n",
        "    val_predictions = torch.cat(val_predictions)\n",
        "\n",
        "    val_accuracy = accuracy_score(\n",
        "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy())\n",
        "    val_precision = precision_score(\n",
        "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(),\n",
        "        average=\"weighted\", zero_division=0)\n",
        "    val_recall = recall_score(\n",
        "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(),\n",
        "        average=\"weighted\", zero_division=0)\n",
        "    val_f1 = f1_score(\n",
        "        val_labels.cpu().numpy(), val_predictions.argmax(dim=1).cpu().numpy(),\n",
        "        average=\"weighted\", zero_division=0)\n",
        "    val_auc = roc_auc_score(\n",
        "        val_labels.cpu().numpy(), val_predictions[:, 1].cpu().numpy())\n",
        "\n",
        "    val_accuracies.append(val_accuracy)\n",
        "    val_precisions.append(val_precision)\n",
        "    val_recalls.append(val_recall)\n",
        "    val_f1_scores.append(val_f1)\n",
        "    val_aucs.append(val_auc)\n",
        "\n",
        "    print(\n",
        "        f\"\\nEpoch {epoch + 1} Summary:\\n\"\n",
        "        f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
        "        f\"Val Loss: {epoch_val_loss:.4f}, \"\n",
        "        f\"Accuracy: {val_accuracy:.3f}, \"\n",
        "        f\"Precision: {val_precision:.3f}, \"\n",
        "        f\"Recall: {val_recall:.3f}, \"\n",
        "        f\"F1: {val_f1:.3f}, \"\n",
        "        f\"AUC: {val_auc:.3f}\"\n",
        "    )\n",
        "\n",
        "    if (epoch + 1) % checkpoint_frequency == 0:\n",
        "        checkpoint_path = f\"/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/224x224/1/model_checkpoint_epoch_{epoch + 1}.pth\"\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Checkpoint saved.\")\n",
        "\n",
        "torch.save(model.state_dict(), last_model_path)\n",
        "print(\"Last model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq9pQioLNiEC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\", marker='x')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='s', color='g')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Validation Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y511r_tQNiED"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ghRe_jjNiED"
      },
      "outputs": [],
      "source": [
        "model_path = \"/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/conventional/BreastMNIST/28x28/1/last_model.pth\"\n",
        "model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "\n",
        "test_loss = 0.0\n",
        "test_labels, test_predictions = [], []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in dataloader_test:\n",
        "        images, labels = images.squeeze(1).to(device), labels.squeeze().to(device)\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        test_loss += loss.item()\n",
        "        test_labels.append(labels)\n",
        "        test_predictions.append(output)\n",
        "\n",
        "test_labels = torch.cat(test_labels)\n",
        "test_predictions = torch.cat(test_predictions)\n",
        "\n",
        "test_probs = torch.exp(test_predictions)\n",
        "\n",
        "test_accuracy = accuracy_score(\n",
        "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy()\n",
        ")\n",
        "test_precision = precision_score(\n",
        "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(),\n",
        "    average=\"weighted\", zero_division=0\n",
        ")\n",
        "test_recall = recall_score(\n",
        "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(),\n",
        "    average=\"weighted\", zero_division=0\n",
        ")\n",
        "test_f1 = f1_score(\n",
        "    test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(),\n",
        "    average=\"weighted\", zero_division=0\n",
        ")\n",
        "test_auc = roc_auc_score(\n",
        "    test_labels.cpu().numpy(), test_probs[:, 1].cpu().numpy()\n",
        ")\n",
        "\n",
        "print(\"\\nFinal Test Evaluation:\")\n",
        "print(f\"Test Loss: {test_loss / len(dataloader_test):.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFF8IbWjNiEE"
      },
      "outputs": [],
      "source": [
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(\n",
        "    test_labels.cpu().numpy(), test_probs[:, 1].cpu().numpy()\n",
        ")\n",
        "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(false_positive_rate, true_positive_rate, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "dataset_name = \"BreastMNIST\"\n",
        "roc_data = pd.DataFrame({\n",
        "    'Dataset': [dataset_name] * len(false_positive_rate),\n",
        "    'False Positive Rate': false_positive_rate,\n",
        "    'True Positive Rate': true_positive_rate,\n",
        "    'Thresholds': thresholds\n",
        "})\n",
        "roc_data.to_csv(f'/home/eflammere/BreastCancerQuanvolution/Quantum/checkpoints/BreastMNIST/224x224/1/roc_curve_data_{dataset_name}.csv', index=False)\n",
        "\n",
        "print(f\"ROC curve data exported to 'roc_curve_data_{dataset_name}.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnDzuUO-NiEE"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(test_labels.cpu().numpy(), test_predictions.argmax(dim=1).cpu().numpy(), labels=[0, 1])\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}