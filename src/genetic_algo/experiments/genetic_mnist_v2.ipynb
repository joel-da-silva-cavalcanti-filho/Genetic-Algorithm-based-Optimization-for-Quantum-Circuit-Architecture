{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9034fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "import random\n",
    "import pennylane\n",
    "import torch\n",
    "import math\n",
    "from math import sqrt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import cmath\n",
    "from torch import tensor, tensordot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnsatzSimulation():\n",
    "\n",
    "\n",
    "    H = [[(1/math.sqrt(2)), (1/math.sqrt(2))], [(1/math.sqrt(2)), -(1/math.sqrt(2))]]\n",
    "\n",
    "    hadamard_gate = tensor(H, dtype=torch.complex64)\n",
    "\n",
    "\n",
    "    pauli_x_gate = tensor([[0.0, 1.0],[1.0 ,0.0]], dtype=torch.complex64)\n",
    "\n",
    "    pauli_y_gate = tensor([[0.0, -1.0j], [1.0j, 0.0]],dtype=torch.complex64)\n",
    "    pauli_z_gate = tensor([[1.0, 0.0], [0.0,-1.0]], dtype=torch.complex64)\n",
    "\n",
    "    phase_gate = tensor([[1.0, 0.0], [0.0, 1.0j]], dtype=torch.complex64)\n",
    "    t_gate = tensor([[1.0, 0.0], [0.0, cmath.exp(math.pi*1.0j/4)]], dtype=torch.complex64)\n",
    "    cnot_gate = tensor([[[[1.+0.j, 0.+0.j],\n",
    "          [0.+0.j, 0.+0.j]],\n",
    "\n",
    "         [[0.+0.j, 1.+0.j],\n",
    "          [0.+0.j, 0.+0.j]]],\n",
    "\n",
    "\n",
    "        [[[0.+0.j, 0.+0.j],\n",
    "          [0.+0.j, 1.+0.j]],\n",
    "\n",
    "         [[0.+0.j, 0.+0.j],\n",
    "          [1.+0.j, 0.+0.j]]]], dtype=torch.complex64)\n",
    "    \n",
    "   \n",
    "\n",
    "    non_parametrized_gates = {\n",
    "        'pauli_x': pauli_x_gate,\n",
    "        'pauli_y': pauli_y_gate,\n",
    "        'pauli_z': pauli_z_gate,\n",
    "        'phase': phase_gate,\n",
    "        't': t_gate,\n",
    "        'hadamard': hadamard_gate\n",
    "    }\n",
    "\n",
    "    def __init__(self, n_qubits: int):\n",
    "        self.n_qubits = n_qubits\n",
    "\n",
    "    # Could do the embedding changing the rotation gates for each angle\n",
    "\n",
    "    def rx_gate(self, theta = math.pi/2):\n",
    "        return tensor([[math.cos(theta/2), -1j*math.sin(theta/2)],\n",
    "                            [-1j*math.sin(theta/2), math.cos(theta/2)]], dtype=torch.complex64)\n",
    "\n",
    "    def ry_gate(self, theta = math.pi/2):\n",
    "        return tensor([[math.cos(theta/2), -math.sin(theta/2)], [math.sin(theta/2), math.cos(theta/2)]], dtype=torch.complex64)\n",
    "\n",
    "    def rz_gate(self, theta = math.pi/2):\n",
    "        return tensor([[-cmath.exp(-1.0j*theta/2), 0.0], [0.0, cmath.exp(-1.0j*theta/2)]], dtype=torch.complex64)\n",
    "    \n",
    "    gate_operation = {\n",
    "        'pauli_x': pauli_x_gate,\n",
    "        'pauli_y': pauli_y_gate,\n",
    "        'pauli_z': pauli_z_gate,\n",
    "        'phase': phase_gate,\n",
    "        't': t_gate,\n",
    "        'hadamard': hadamard_gate\n",
    "    }\n",
    "\n",
    "    def rotation_states(self, patch_vector, rotation_gate):\n",
    "        state_vector = rotation_gate(patch_vector[0])\n",
    "        for index in range(0, len(patch_vector) - 1):\n",
    "            state_vector = torch.kron(state_vector, rotation_gate(patch_vector[index+1]))\n",
    "\n",
    "        return state_vector\n",
    "       \n",
    "    \n",
    "    def rx_state(self, angle):\n",
    "        return tensor([[math.cos(angle/2), -1j*math.sin(angle/2)],\n",
    "                            [-1j*math.sin(angle/2), math.cos(angle/2)]], dtype=torch.complex64)\n",
    "\n",
    "    def ry_state(self, angle):\n",
    "        return tensor([[math.cos(angle/2), -math.sin(angle/2)], [math.sin(angle/2), math.cos(angle/2)]], dtype=torch.complex64)\n",
    "    \n",
    "    def rz_state(self, angle):\n",
    "        return tensor([[-cmath.exp(-1.0j*angle/2), 0.0], [0.0, cmath.exp(-1.0j*angle/2)]], dtype=torch.complex64)\n",
    "    \n",
    "    rotation_function = {\n",
    "        'rx': rx_state,\n",
    "        'ry': ry_state,\n",
    "        'rz': rz_state\n",
    "    }\n",
    "    \n",
    "    def randomAngleEmbedding(self, angle_tensor):\n",
    "        rotation_gate_options = ['rx', 'ry', 'rz']\n",
    "        angle_count = 0\n",
    "        eye_tensor = torch.zeros(2**self.n_qubits, dtype=torch.complex64)\n",
    "        eye_tensor[0] = 1.0\n",
    "        for angle in angle_tensor:\n",
    "            random.seed(520)\n",
    "            chosen_gate = random.choice(rotation_gate_options)\n",
    "            if angle_count == 0:\n",
    "                state_vector = self.rotation_function[chosen_gate](self, angle)\n",
    "            else:\n",
    "                new_vector = self.rotation_function[chosen_gate](self, angle)\n",
    "                state_vector = torch.kron(state_vector, new_vector)\n",
    "            angle_count+=1\n",
    "            \n",
    "        return state_vector @ eye_tensor\n",
    "\n",
    "    def uniformAngleEmbedding(self, patch_vector, rotation_gate: str):\n",
    "        eye_tensor = torch.zeros(2**self.n_qubits, dtype=torch.complex64)\n",
    "        eye_tensor[0] = 1.0\n",
    "        if rotation_gate == 'rx':\n",
    "            return self.rotation_states(patch_vector, self.rx_gate) @ eye_tensor\n",
    "        elif rotation_gate == 'ry':\n",
    "            return self.rotation_states(patch_vector, self.ry_gate) @ eye_tensor\n",
    "\n",
    "        elif rotation_gate == 'rz':\n",
    "            return self.rotation_states(patch_vector, self.rz_gate)  @ eye_tensor\n",
    "        \n",
    "\n",
    "    # Instead of simulating one qubit gate per time just do kronecker product to create a layer of quantum gates\n",
    "    # To link all layers just do matmul\n",
    "\n",
    "    # Also for simulating a controlled not gate, just do the tensor product between dims=([2,3], [control, target])\n",
    "    # Tensor product between gates of the same layer would be better tbh, so just do\n",
    "\n",
    "    def simulate_one_qubit_gate(self, selected_gate: torch.Tensor, state_vector: torch.Tensor, selected_qubit:int) -> tensor:\n",
    "        return tensordot(selected_gate, state_vector, dims=([1],[selected_qubit]))\n",
    "\n",
    "    def simulate_cnot(self, state_vector: torch.Tensor, target_qubit: int, control_qubit: int) -> tensor:\n",
    "        return tensordot(self.cnot_gate, state_vector, dims=([2,3],[control_qubit, target_qubit]))\n",
    "\n",
    "    def simulate_rotation_gate(self, selected_gate, state_vector, selected_qubit, angle=math.pi/2):\n",
    "        rotation_tensor = self.rotation_function[selected_gate](self, angle)\n",
    "        return tensordot(rotation_tensor, state_vector, dims=([1],[selected_qubit]))\n",
    "\n",
    "    # Fix pauli Z measurement\n",
    "    def pauliZ_test(self, state_vector, qubit_index):\n",
    "        bitmask = 1 << qubit_index\n",
    "        conjugated_state_vector = torch.conj(state_vector)\n",
    "\n",
    "        for index in range(0, 2**self.n_qubits):\n",
    "            if index & bitmask != 0:\n",
    "                state_vector[index] = -state_vector[index]\n",
    "\n",
    "        return torch.sum(conjugated_state_vector * state_vector)\n",
    "    \n",
    "    def pauliZ_expectationValue(self, state_vector, qubit_index):\n",
    "        indices = torch.arange(2**self.n_qubits)\n",
    "        signs = 1 - 2*((indices >> qubit_index) & 1)  # +1 for 0, -1 for 1\n",
    "        expectation = torch.sum(signs * torch.abs(state_vector)**2)\n",
    "        \n",
    "        return expectation\n",
    "\n",
    "\n",
    "    def simulate_circuit(self, input: torch.Tensor, embedding_type: str, ansatz_chromosome: list, parameters: torch.Tensor, measure: bool):\n",
    "        layer_count = 0\n",
    "        angle_count = 0\n",
    "        #print('Starting ansatz simulation...')\n",
    "        #start_time = time.perf_counter()\n",
    "        state_vector = self.uniformAngleEmbedding(input, embedding_type).view((2,)*self.n_qubits)\n",
    "        \n",
    "        for layer in ansatz_chromosome:\n",
    "            #print(f'Starting simulation at layer #{layer_count}')\n",
    "            qubit_count = 0\n",
    "            cnot_stack = []\n",
    "            for gate in layer:\n",
    "                #print(f'Starting simulation at qubit {qubit_count}... ')\n",
    "                if gate in self.gate_operation:\n",
    "                    state_vector = self.simulate_one_qubit_gate(self.gate_operation[gate], state_vector, qubit_count)\n",
    "                elif gate in self.rotation_function:\n",
    "                   # random_angle = random.uniform(0.0, 1.5)*math.pi\n",
    "                    state_vector = self.simulate_rotation_gate(gate, state_vector, qubit_count, parameters[angle_count])\n",
    "                    angle_count+=1\n",
    "                elif gate != 'empty':\n",
    "                    if gate[0:4] == 'ctrl' or gate[0:4] == 'trgt':\n",
    "                        if not cnot_stack:\n",
    "                            cnot_stack.append([gate[0:4], qubit_count])\n",
    "                        else:\n",
    "                            if gate[0:4] == 'trgt':\n",
    "                                target_qubit = qubit_count\n",
    "                                gate_name, control_qubit = cnot_stack[-1]\n",
    "            \n",
    "                            if gate[0:4] == 'ctrl':\n",
    "                                control_qubit = qubit_count\n",
    "                                gate_name, target_qubit = cnot_stack[-1]\n",
    "\n",
    "                            state_vector = self.simulate_cnot(state_vector, target_qubit, control_qubit)\n",
    "                            cnot_stack.pop()\n",
    "\n",
    "                #print(f'Simulation at qubit {qubit_count} done!')\n",
    "\n",
    "                qubit_count+=1\n",
    "            layer_count+=1\n",
    "\n",
    "        #end_time = time.perf_counter()\n",
    "        #print(f'Simulation processing time: {end_time - start_time}')\n",
    "        if measure:   \n",
    "            state_vector = state_vector.view(-1)\n",
    "            return [self.pauliZ_expectationValue(state_vector, qubit_index) for qubit_index in range(self.n_qubits)]\n",
    "        else:\n",
    "            return state_vector.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb337eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    def __init__(self, crossover_rate: float, mutation_rate: float, no_generations: int, population_size: int, sampling, fitness, crossover, mutation, duplicates):\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.no_generations = no_generations\n",
    "        self.population_size = population_size\n",
    "\n",
    "        self.Sampling = sampling\n",
    "        self.Fitness = fitness\n",
    "        self.Crossover = crossover\n",
    "        self.Mutation = mutation\n",
    "        self.eliminate_duplicates = duplicates\n",
    "\n",
    "    ## Population deve ter dimensões (population_size, solution_size)\n",
    "\n",
    "    def initialize_population(self):\n",
    "        return self.Sampling._do(self.population_size)\n",
    "  \n",
    "    def define_fitness(self, population, iteration) -> np.array:\n",
    "        return np.array([self.Fitness._evaluate(individual, iteration, population.index(individual)) for individual in population])\n",
    "\n",
    "    def select_parents(self, population: list):\n",
    "\n",
    "        random_generator = np.random.default_rng(seed=42)\n",
    "        indices = random_generator.choice(len(population), 2, replace=False)\n",
    "        parent_a = population[indices[0]]\n",
    "        parent_b = population[indices[1]]\n",
    "        \n",
    "        if len(parent_a) < len(parent_b):\n",
    "            parent_a, parent_b = parent_b, parent_a\n",
    "        return parent_a, parent_b\n",
    "\n",
    "    def choose_parent(self) -> int:\n",
    "        options = [0, 1]\n",
    "        return random.choice(options)\n",
    "    \n",
    "    def crossover(self, parent_a, parent_b):\n",
    "        return self.Crossover._do(parent_a, parent_b)\n",
    "\n",
    "    def mutate_offspring(self, offspring) -> np.array:\n",
    "        return self.Mutation._do(offspring)\n",
    "    \n",
    "    ## Use fitness values for elitism or something\n",
    "\n",
    "\n",
    "    def run_algorithm(self) -> tuple:\n",
    "        iterations = 0\n",
    "        old_population = self.initialize_population()\n",
    "        iteration_axis = []\n",
    "        best_chromossome_axis = []\n",
    "        while iterations != self.no_generations:\n",
    "            print(old_population)\n",
    "            print(f\"iteration #{iterations}\")\n",
    "            iteration_axis.append(iterations)\n",
    "            old_fitness_values = self.define_fitness(old_population, iterations)\n",
    "            new_population = []\n",
    "            for individuals in range(int(self.population_size/2)):\n",
    "                parent_a, parent_b = self.select_parents(old_population)\n",
    "                offspring_a, offspring_b = self.mutate_offspring(self.crossover(parent_a, parent_b))\n",
    "                new_population.append(offspring_a)\n",
    "                new_population.append(offspring_b)\n",
    "            \n",
    "            iterations +=1\n",
    "\n",
    "            old_best_individual_position = np.argmax(old_fitness_values)\n",
    "            old_best_fitness_value = np.max(old_fitness_values)\n",
    "            old_best_individual = old_population[old_best_individual_position]\n",
    "\n",
    "            new_fitness_values = self.define_fitness(new_population, iterations)\n",
    "            new_best_individual_position = np.argmax(new_fitness_values)\n",
    "            new_best_fitness_value = np.max(new_fitness_values)\n",
    "            new_best_individual = new_population[new_best_individual_position]\n",
    "        \n",
    "            current_best_individual_fitness = 0.0\n",
    "            if new_best_fitness_value > old_best_fitness_value:\n",
    "                current_best_individual_fitness = new_best_fitness_value\n",
    "                current_best_individual = new_best_individual\n",
    "            else:\n",
    "                current_best_individual_fitness = old_best_fitness_value\n",
    "                current_best_individual = old_best_individual\n",
    "\n",
    "    \n",
    "            result_tuple = (current_best_individual, current_best_individual_fitness)\n",
    "            best_chromossome_axis.append(current_best_individual_fitness)\n",
    "        \n",
    "            old_best_individual_position = np.argmax(old_fitness_values)\n",
    "            random_position = random.randint(0, self.population_size - 1)\n",
    "            new_population[random_position] = old_population[old_best_individual_position]\n",
    "            old_population = new_population\n",
    "            \n",
    "        \n",
    "        return result_tuple, best_chromossome_axis, iteration_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dce752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuanvLayer(nn.Module):\n",
    "    def __init__(self, n_qubits, patch_size, chromosome, mode=\"frozen\"):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.patch_size = patch_size\n",
    "        self.chromosome = chromosome\n",
    "        \n",
    "        gates = list(itertools.chain.from_iterable(chromosome))\n",
    "        gate_count = Counter(gates)\n",
    "        n_params = gate_count['rx_gate'] + gate_count['ry_gate'] + gate_count['rz_gate']\n",
    "        if mode == \"frozen\":\n",
    "            self.ansatz_params = torch.rand(n_params)*math.pi\n",
    "        elif mode == \"trainable\":\n",
    "            self.ansatz_params = nn.Parameter(torch.rand(n_params)*math.pi)\n",
    "            \n",
    "        self.qlayer = AnsatzSimulation(n_qubits)\n",
    "        \n",
    "    def multichannel_quanv_2d(self, x):\n",
    "        \n",
    "        outputs = [[[self.qlayer.simulate_circuit(patch, 'ry', self.chromosome, self.ansatz_params, True) for patch in patches] for patches in channel] for channel in x]\n",
    "        n_images, n_channels, n_patches, patch_size = tensor(outputs).shape\n",
    "        image_size = int((n_patches * patch_size) ** 0.5)\n",
    "        \n",
    "        return tensor(outputs).view(n_images, image_size, image_size, n_channels)\n",
    "    \n",
    "    def greyscale_quanv_2d(self, x):\n",
    "        \n",
    "        outputs = [[self.qlayer.simulate_circuit(patch, 'rx', self.chromosome, self.ansatz_params, True) for patch in patches] for patches in x]\n",
    "        \n",
    "        return tensor(outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 4:\n",
    "            return self.multichannel_quanv_2d(x)\n",
    "        elif len(x.shape) == 3:\n",
    "            return self.greyscale_quanv_2d(x)\n",
    "        \n",
    "    \n",
    " \n",
    "class L2NormalizationLayer(nn.Module):\n",
    "    def __init__(self, dim=1, eps=1e-12):\n",
    "        super(L2NormalizationLayer, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, p=2, dim=self.dim, eps=self.eps)\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, n_qubits, patch_size, chromosome, num_classes, input_size, mode='frozen'):\n",
    "        super().__init__()\n",
    "        self.quanv_layer = QuanvLayer(\n",
    "            n_qubits=n_qubits,\n",
    "            patch_size=patch_size,\n",
    "            chromosome=chromosome,\n",
    "            mode=mode\n",
    "        )\n",
    "        feature_size = input_size**2\n",
    "        self.fc1 = nn.Linear(feature_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.norm = nn.LayerNorm(feature_size)\n",
    "        #self.conv1 = nn.Conv2d(in_channels = 1, output_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=patch_size, stride=patch_size)\n",
    "        self.fc = nn.Linear(feature_size, num_classes)\n",
    "        self.l2norm = L2NormalizationLayer(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"Passing through quanvolution layer...\")\n",
    "        start_time = time.perf_counter()\n",
    "        x = self.quanv_layer.forward(x)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f'Quanvolution processing time: {end_time - start_time}')  \n",
    "        x = x.flatten(start_dim=1)\n",
    "        #print(x.shape)\n",
    "        x = self.l2norm(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "def train_model(model, train_loader, num_epochs, optimizer, loss_fn, filepath):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        epoch_loss = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for i, (inputs, labels) in progress_bar:\n",
    "        \n",
    "            optimizer.zero_grad()  # Zero out previous gradients\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)  # Calculate loss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            loss.backward()  # Backpropagate to calculate gradients\n",
    "            optimizer.step() # Update weights\n",
    "            \n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/(i+1):.4f}, Acc: {correct / total:.4f}\")\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={epoch_loss:.4f}, Train Acc={epoch_acc:.4f}\")\n",
    "            # Print every 10 batches\n",
    "            \n",
    "    torch.save(model.state_dict(), filepath)  \n",
    "    \n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()    \n",
    "    model.to(device)\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "#            images = images.to(device)\n",
    "#            labels = labels.squeeze().to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy() if outputs.shape[1] > 1 else torch.softmax(outputs, dim=1)[:, 0].cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_predictions.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1, auc\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616ac73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_cnot_gate(circuit_layer: list, selected_qubit: int):\n",
    "    \"\"\"\n",
    "    This function swaps the control and target qubits in \n",
    "    the CNOT gate\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    gate = circuit_layer[selected_qubit]\n",
    "    if gate[0:4] == 'ctrl': # testar esse if\n",
    "        cnot_value = gate[5]\n",
    "        target_index = circuit_layer.index('trgt_'+ cnot_value)\n",
    "        circuit_layer[selected_qubit], circuit_layer[target_index] =  circuit_layer[target_index], circuit_layer[selected_qubit] \n",
    "    elif gate[0:4] == 'trgt':\n",
    "        cnot_value = gate[5]\n",
    "        control_index = circuit_layer.index('ctrl_' + cnot_value)\n",
    "        circuit_layer[selected_qubit], circuit_layer[control_index] =  circuit_layer[control_index], circuit_layer[selected_qubit]\n",
    "    \n",
    "    return circuit_layer\n",
    "\n",
    "def change_cnot_gate_to_one_qubit_gates(circuit_layer: list, gate_options: list, selected_qubit: int) -> list:\n",
    "\n",
    "    \"\"\"\n",
    "    This function turns the control and target qubits into one-qubit gates\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    gate = circuit_layer[selected_qubit]\n",
    "    gate_index = gate[5]\n",
    "    if gate[0:4] == 'ctrl':\n",
    "        target_index = circuit_layer.index('trgt_' + gate_index)\n",
    "        circuit_layer[control_index] = np.random.choice(gate_options)\n",
    "    elif gate[0:4] == 'trgt':\n",
    "        control_index = circuit_layer.index('ctrl_' + gate_index)\n",
    "        circuit_layer[control_index] = np.random.choice(gate_options)\n",
    "    \n",
    "    circuit_layer[selected_qubit] = np.random.choice(gate_options)\n",
    "    \n",
    "    return circuit_layer\n",
    "\n",
    "class AnsatzMutation:\n",
    "\n",
    "    \"\"\"\n",
    "    This Mutation Class randomly swaps Ansatz layers and changes the  \n",
    "    the gates placed in certain positions\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, mutation_rate: float):\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.one_qubit_gates = ['empty', 'pauli_x', 'pauli_y','pauli_z','rx_gate','ry_gate','rz_gate','phase','t','hadamard']\n",
    "        self.gate_options_with_cnot = ['pauli_x', 'pauli_y','pauli_z','rx_gate','ry_gate','rz_gate','phase','t','hadamard', 'ctrl', 'trgt']\n",
    "\n",
    "    def _do(self, offspring):\n",
    "        mutated_offspring = []\n",
    "        for individual in offspring:\n",
    "            mutated_individual = []\n",
    "            for circuit_layer in individual:\n",
    "                random_value = np.random.random()\n",
    "                if random_value < self.mutation_rate:\n",
    "                    random_qubit_position = np.random.randint(0, len(circuit_layer))\n",
    "                    random_gate =  circuit_layer[random_qubit_position]\n",
    "                    if random_gate[0:4] == 'ctrl' or random_gate[0:4] == 'trgt': \n",
    "                        random_mutation_action = np.random.randint(0,2)\n",
    "                        random_qubit_position = np.random.randint(0, len(circuit_layer))\n",
    "                        if random_mutation_action == 0:\n",
    "                            mutated_individual.append(swap_cnot_gate(circuit_layer, random_qubit_position))\n",
    "                        elif random_mutation_action == 1:\n",
    "                            mutated_individual.append(change_cnot_gate_to_one_qubit_gates(circuit_layer, self.one_qubit_gates, random_qubit_position))\n",
    "                    else:\n",
    "                        new_layer = circuit_layer\n",
    "                        new_layer[random_qubit_position] = random.choice(self.gate_options_with_cnot)\n",
    "                        mutated_individual.append(new_layer)\n",
    "                else:\n",
    "                    mutated_individual.append(circuit_layer)\n",
    "            mutated_offspring.append(mutated_individual)\n",
    "\n",
    "        print(len(mutated_offspring))\n",
    "        offspring_a, offspring_b = mutated_offspring\n",
    "        return offspring_a, offspring_b\n",
    "    \n",
    "def select_parents(population: list):\n",
    "    random_generator = np.random.default_rng(seed=42)\n",
    "    parent_a, parent_b = random_generator.choice(a = np.array(population), size=2, replace=False)\n",
    "    if parent_a.shape[1] < parent_b.shape[1]:\n",
    "        parent_a, parent_b = parent_b, parent_a\n",
    "    return parent_a, parent_b\n",
    "\n",
    "\n",
    "# Gotta test AnsatzCrossover\n",
    "class AnsatzCrossover:\n",
    "    \"\"\"\"\n",
    "    The crossover happens between chromosomes of possibly different lengths,\n",
    "    then the offspring might inherit the size of one of its parents\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, crossover_rate: float):\n",
    "        self.crossover_rate = crossover_rate\n",
    "\n",
    "    def _do(self, parent_a, parent_b):\n",
    "        random_number = np.random.random()\n",
    "        if random_number < self.crossover_rate:\n",
    "            return [parent_a, parent_b]\n",
    "        \n",
    "        random_generator = np.random.default_rng(seed=42)\n",
    "\n",
    "        # The parent b is always the smallest one, and the parent a, the biggest one\n",
    "\n",
    "        chromosome_length_a = len(parent_b)\n",
    "        chromosome_length_b = len(parent_a)\n",
    "\n",
    "        crossover_point_a = random_generator.integers(low=2, high=chromosome_length_a, size=1)[0]\n",
    "        crossover_point_b = random_generator.integers(low=2, high=chromosome_length_b,size=1)[0]\n",
    "\n",
    "        # Could flip a coin to change which parent comes first\n",
    "        flip_coin = random_generator.choice([0, 1])\n",
    "\n",
    "        if flip_coin == 0:\n",
    "            offspring_a = parent_a[0:crossover_point_a] + parent_b[crossover_point_b:]\n",
    "            offspring_b = parent_b[0:crossover_point_b] + parent_a[crossover_point_a:]\n",
    "        else:\n",
    "            offspring_a = parent_b[0:crossover_point_b] + parent_a[crossover_point_a:]\n",
    "            offspring_b = parent_a[0:crossover_point_a] + parent_b[crossover_point_b:]\n",
    "\n",
    "    \n",
    "        return [offspring_a, offspring_b]\n",
    "    \n",
    "class RemoveEquivalentAnsätze:\n",
    "\n",
    "    def __init__(self, n_tests, threshold_value, n_qubits):\n",
    "        self.n_tests = n_tests\n",
    "        self.threshold_value = threshold_value\n",
    "        self.n_qubits = n_qubits\n",
    "        self.circuit_ansatz = AnsatzSimulation(self.n_qubits)\n",
    "        \n",
    "        \n",
    "\n",
    "    def generate_random_parameters(self, ansatz):\n",
    "        gates = list(itertools.chain.from_iterable(ansatz.tolist()))\n",
    "        gate_count = Counter(gates)\n",
    "        n_params = gate_count['rx_gate'] + gate_count['ry_gate'] + gate_count['rz_gate']\n",
    "        parameters = torch.rand(n_params)*math.pi\n",
    "\n",
    "        return parameters\n",
    "\n",
    "    def test_ansatz(self, ansatz, parameters, state_vector):\n",
    "        return self.circuit_ansatz.simulate_circuit(input=state_vector, embedding_type='rx', ansatz_chromosome=ansatz, parameters=parameters, measure=False)\n",
    "            \n",
    "    # Check whether i calculate the inner product with just the real parts or should i include the imaginary ones as well\n",
    "   \n",
    "    def fidelity(self, state_vector_psi, state_vector_phi):\n",
    "        return 1 - torch.einsum('i,i->i',state_vector_psi, state_vector_phi)**2\n",
    "\n",
    "    # Decide which measure should be used in order to evaluate the\n",
    "\n",
    "    def is_equal(self, ansatz_a, ansatz_b):\n",
    "        print(type(ansatz_a))\n",
    "        ansatz_a = ansatz_a.tolist()\n",
    "        ansatz_b = ansatz_b.tolist()\n",
    "        input_test = torch.rand(self.n_tests, self.n_qubits)\n",
    "        params_a = self.generate_random_parameters(ansatz_a)\n",
    "        params_b = self.generate_random_parameters(ansatz_b)\n",
    "        \n",
    "        output_a = [self.test_ansatz(ansatz_a, params_a, state_vector) for state_vector in input_test]\n",
    "        output_b = [self.test_ansatz(ansatz_b, params_b, state_vector) for state_vector in input_test]\n",
    "        output_pair = list(zip(output_a, output_b))\n",
    "        \n",
    "        fidelity_score = torch([self.fidelity(state_psi, state_phi) for (state_psi, state_phi) in output_pair])\n",
    "        \n",
    "        score = torch.mean(fidelity_score)\n",
    "        \n",
    "        return self.threshold_value > score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a0555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['pauli_y', 'pauli_x', 'ctrl_0', 'trgt_0'],\n",
       "  ['ry_gate', 'pauli_x', 'phase', 't'],\n",
       "  ['ctrl_0', 'trgt_0', 'phase', 'pauli_z'],\n",
       "  ['t', 'rx_gate', 'phase', 'pauli_z'],\n",
       "  ['phase', 'pauli_x', 'ry_gate', 't']],\n",
       " [['pauli_z', 'trgt', 'pauli_z', 'pauli_y'],\n",
       "  ['ctrl_0', 'trgt_0', 'ctrl_1', 'trgt_1'],\n",
       "  ['pauli_x', 'ctrl_0', 'trgt_0', 'pauli_z'],\n",
       "  ['ry_gate', 'ry_gate', 'rx_gate', 'rx_gate']])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutation_rate = 0.1\n",
    "offsprings = [[['pauli_y', 'pauli_x', 'ctrl_0', 'trgt_0'], ['ry_gate', 'pauli_x', 'phase', 't'], ['ctrl_0', 'trgt_0', 'phase', 'pauli_z'], ['t', 'rx_gate', 'phase', 'pauli_z'], ['phase', 'pauli_x', 'ry_gate', 't']], [['pauli_z', 'trgt', 'pauli_z', 'pauli_y'], ['ctrl_0', 'trgt_0', 'ctrl_1', 'trgt_1'], ['pauli_x', 'ctrl_0', 'trgt_0', 'pauli_x'], ['ry_gate', 'ry_gate', 'rx_gate', 'rx_gate']]]\n",
    "mutate = AnsatzMutation(mutation_rate)\n",
    "mutate._do(offsprings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fafbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuitOptimization:\n",
    "    def __init__(self, n_qubits, n_gates, possible_gates, n_layers, patch_size, n_classes, input_size, mode, max_gates, dataset, batch_size, train_ratio):\n",
    "        self.n_gates = n_gates,\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers \n",
    "        self.possible_gates = possible_gates\n",
    "        self.patch_size = patch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.input_size = input_size \n",
    "        self.mode = mode\n",
    "        self.max_gates = max_gates\n",
    "        \n",
    "        \n",
    "\n",
    "        train_len=int(len(dataset)*train_ratio)\n",
    "        test_len=len(dataset)-int(len(dataset)*train_ratio)\n",
    "        train_set= Subset(dataset,range(0,train_len))\n",
    "        val_set=Subset(dataset,range(train_len,len(dataset)))\n",
    "                \n",
    "        \n",
    "        self.train_load = DataLoader(train_set, batch_size, shuffle=True)\n",
    "        self.val_load = DataLoader(val_set, batch_size, shuffle=True)\n",
    "        \n",
    "    def _evaluate(self, x, generation, individual):\n",
    "\n",
    "        # Amount of layers * # of qubits\n",
    "        ansatz_depth = len(x) * self.n_qubits\n",
    "        if ansatz_depth > self.max_gates:\n",
    "            return max(0, ansatz_depth - self.max_gates)\n",
    "        else:\n",
    "            hqcnn = HybridModel(self.n_qubits, self.patch_size, x, self.n_classes, self.input_size, self.mode)\n",
    "            optimizer = torch.optim.Adam(hqcnn.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "            device = torch.device(\"cpu\")\n",
    "            n_epochs = 5\n",
    "            \n",
    "            filepath = f'weights/mnist_hqcnn_GA_gen_#{generation}_individual_#{individual}'\n",
    "            train_model(hqcnn, self.train_load, n_epochs, optimizer, loss_fn, filepath)\n",
    "           \n",
    "            val_hqcnn = HybridModel(self.n_qubits, self.patch_size, x, self.n_classes, self.input_size, self.mode)\n",
    "            val_hqcnn.load_state_dict(torch.load(filepath, weights_only=True))\n",
    "            avg_loss, accuracy, precision, recall, f1, auc = validate_model(hqcnn, self.val_load, loss_fn, device)\n",
    "            return -f1\n",
    "\n",
    "# Gotta test if sampling is working\n",
    "class AnsatzRepair:\n",
    "\n",
    "    def _do(self, X):\n",
    "        return X\n",
    "\n",
    "\n",
    "class QuantumCircuitSampling:\n",
    "    \n",
    "    def __init__(self, n_qubits):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.quantum_gate_options = ['empty', 'pauli_x', 'pauli_y','pauli_z','rx_gate','ry_gate','rz_gate','phase','t','hadamard', 'ctrl', 'trgt']\n",
    "        self.gate_options_without_cnot = ['pauli_x', 'pauli_y','pauli_z','rx_gate','ry_gate','rz_gate','phase','t','hadamard']\n",
    "        self.rotation_gate_options = ['rx_gate', 'ry_gate', 'rz_gate']\n",
    "        self.non_parametrized_gates = ['pauli_x', 'pauli_y','pauli_z', 'phase','t','hadamard', 'ctrl', 'trgt']\n",
    "    \n",
    "    def generate_layer_without_entanglement(self):\n",
    "       return [random.choice(self.gate_options_without_cnot) for wire in range(self.n_qubits)]\n",
    "    \n",
    "    def generate_rotation_layer(self):\n",
    "        return [random.choice(self.rotation_gate_options) for wire in range(self.n_qubits)]\n",
    "    \n",
    "    def place_a_single_gate(self):\n",
    "        return random.choice(self.gate_options_without_cnot) \n",
    "    \n",
    "    def generate_disjoint_cnots(self):\n",
    "        cnot_count_layer_one = 0\n",
    "        cnot_count_layer_two = 0\n",
    "        layer_one = []\n",
    "        layer_two = []\n",
    "        \n",
    "        layer_two.append(self.place_a_single_gate())\n",
    "        \n",
    "        for wire in range(self.n_qubits - 1):\n",
    "            if wire%2 == 0:\n",
    "                layer_one.append(f'ctrl_{cnot_count_layer_one}')\n",
    "                layer_one.append(f'trgt_{cnot_count_layer_one}')\n",
    "                cnot_count_layer_one += 1\n",
    "               \n",
    "            else:\n",
    "                layer_two.append(f'ctrl_{cnot_count_layer_two}')\n",
    "                layer_two.append(f'trgt_{cnot_count_layer_two}')\n",
    "                cnot_count_layer_two += 1\n",
    "            \n",
    "        if self.n_qubits%2 == 0:\n",
    "            layer_two.append(self.place_a_single_gate())\n",
    "        else:\n",
    "            layer_one.append(self.place_a_single_gate())\n",
    "        \n",
    "        return layer_one, layer_two\n",
    "    \n",
    "    def generate_non_parametrized_layer(self):\n",
    "        return [random.choice(self.non_parametrized_gates) for wire in range(self.n_qubits)]\n",
    "\n",
    "    def generate_partially_entangled_layer(self):\n",
    "        pairs = [(wire,wire+1) for wire in range(self.n_qubits-1)]\n",
    "        #print(pairs)\n",
    "        selected_pair = random.choice(pairs)\n",
    "        control, target = selected_pair\n",
    "        layer = ['ctrl_0' if wire == control else\n",
    "                'trgt_0' if wire == target else\n",
    "                self.place_a_single_gate()\n",
    "                for wire in range(self.n_qubits)]\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "    def _do(self, n_samples):\n",
    "        print('where are you?')\n",
    "        population = []\n",
    "        \n",
    "        for individual in range(n_samples):\n",
    "            print(f'Generating individual...')\n",
    "            ansatz = []\n",
    "            n_layers = random.randint(4, 10)\n",
    "            print(f'Generating {n_layers} layers...')\n",
    "            depth = 0\n",
    "            while depth != n_layers:\n",
    "                print(f'Generating layer #{depth}')\n",
    "                gate_layer = []\n",
    "                layer_type = random.randint(0,4)\n",
    "                if layer_type == 0:\n",
    "                    layer = self.generate_layer_without_entanglement()\n",
    "                    ansatz.append(layer)\n",
    "                    depth+=1\n",
    "                elif layer_type == 1:\n",
    "                    layer_one, layer_two = self.generate_disjoint_cnots()\n",
    "                    ansatz.append(layer_one)\n",
    "                    ansatz.append(layer_two) \n",
    "                    depth+=2\n",
    "                elif layer_type == 2:\n",
    "                    layer = self.generate_rotation_layer()\n",
    "                    ansatz.append(layer)\n",
    "                    depth+=1\n",
    "                elif layer_type == 3:\n",
    "                    layer = self.generate_non_parametrized_layer()\n",
    "                    ansatz.append(layer)\n",
    "                    depth+=1\n",
    "                elif layer_type == 4:\n",
    "                    layer = self.generate_partially_entangled_layer()\n",
    "                    ansatz.append(layer)\n",
    "                    depth+=1\n",
    "            population.append(ansatz)\n",
    "                           \n",
    "        return population\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(dataset, classes, sample_size):\n",
    "    class_one = 0\n",
    "    class_two = 0\n",
    "    binary_dataset = []\n",
    "\n",
    "    for image in tqdm(dataset, desc='sampling data'):\n",
    "        if image[1] == classes[0] and class_one < sample_size:\n",
    "            binary_dataset.append(image)\n",
    "            class_one +=1 \n",
    "        elif image[1] == classes[1] and class_two < sample_size:\n",
    "            binary_dataset.append(image)\n",
    "            class_two += 1\n",
    "            \n",
    "        if class_one == sample_size and class_two == sample_size:\n",
    "            break\n",
    "    \n",
    "    return binary_dataset\n",
    "\n",
    "class SampledDataset4Training(Dataset):\n",
    "    def __init__(self, dataset, target_classes, transform=None):\n",
    "        images, labels = zip(*dataset)\n",
    "        labels = [0 if label == target_classes[0] else 1 for label in tqdm(labels, desc='labeling')]\n",
    "        self.labels = tensor(labels)\n",
    "        self.images = torch.stack(images)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(self.images[index])\n",
    "        else:\n",
    "            sample = self.images[index]\n",
    "        \n",
    "        \n",
    "        return sample, self.labels[index]\n",
    "\n",
    "class PatchExtraction(object):\n",
    "    def __init__(self, patch_size: int):\n",
    "        self.patch_size = patch_size\n",
    "    \n",
    "    def __call__(self, image):\n",
    "    \n",
    "        unfold = nn.Unfold(kernel_size=(self.patch_size, self.patch_size), stride=self.patch_size)\n",
    "        image_patches = unfold(image)\n",
    "        patch_len, n_patches = image_patches.shape\n",
    "        image_patches = image_patches.view((n_patches, patch_len))\n",
    "        return image_patches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65509181",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 2\n",
    "crossover_rate = 0.5\n",
    "mutation_rate = 0.1\n",
    "generations = 2\n",
    "seed = 42\n",
    "\n",
    "# Circuit ansatz hyperparameters\n",
    "n_tests = 4\n",
    "equivalence_ratio = 0.7\n",
    "n_qubits = 4\n",
    "max_gates = 32\n",
    "gate_options = [None, 'pauli_x', 'pauli_y','pauli_z','rx_gate','ry_gate','rz_gate','phase','t','hadamard', 'ctrl', 'trgt']\n",
    "max_layers = 8\n",
    "\n",
    "# Model and training hyperparameters\n",
    "input_size = 20\n",
    "n_classes = 2\n",
    "mode = 'frozen'\n",
    "batch_size = 50\n",
    "train_ratio = 0.7\n",
    "patch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8db55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    PatchExtraction(patch_size)])\n",
    "\n",
    "target_classes = [0, 1]\n",
    "sample_size = 200\n",
    "\n",
    "full_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "sampled_training_dataset = sample_data(full_trainset, target_classes, sample_size)\n",
    "mnist_training_dataset = SampledDataset4Training(sampled_training_dataset, target_classes)\n",
    "\n",
    "\n",
    "ansatz_optimization_problem = QuantumCircuitOptimization(n_qubits=n_qubits,\n",
    "                                                            n_gates=max_gates,\n",
    "                                                            possible_gates=gate_options,\n",
    "                                                            n_layers=max_layers,\n",
    "                                                            patch_size=patch_size,\n",
    "                                                            max_gates=max_gates,\n",
    "                                                            input_size=input_size,\n",
    "                                                            n_classes=n_classes,\n",
    "                                                            mode=mode,\n",
    "                                                            dataset=mnist_training_dataset,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            train_ratio=train_ratio)\n",
    "\n",
    "duplicate_ansatz = RemoveEquivalentAnsätze(n_tests, equivalence_ratio, n_qubits)\n",
    "\n",
    "genetic_algo = GeneticAlgorithm(crossover_rate=crossover_rate,\n",
    "                                mutation_rate=mutation_rate,\n",
    "                                no_generations=generations,\n",
    "                                population_size=population_size,\n",
    "                                sampling=QuantumCircuitSampling(n_qubits),\n",
    "                                fitness=ansatz_optimization_problem,\n",
    "                                crossover=AnsatzCrossover(crossover_rate),\n",
    "                                mutation=AnsatzMutation(mutation_rate),\n",
    "                                duplicates=duplicate_ansatz)\n",
    "\n",
    "result, best_solution_axis, iterations = genetic_algo.run_algorithm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87689576",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsprings = [[['pauli_y', 'pauli_x', 'ctrl_0', 'trgt_0'], ['ry_gate', 'pauli_x', 'phase', 't'], ['ctrl_0', 'trgt_0', 'phase', 'pauli_z'], ['t', 'rx_gate', 'phase', 'pauli_z'], ['phase', 'pauli_x', 'ry_gate', 't']], [['pauli_z', 'trgt', 'pauli_z', 'pauli_y'], ['ctrl_0', 'trgt_0', 'ctrl_1', 'trgt_1'], ['pauli_x', 'ctrl_0', 'trgt_0', 'pauli_x'], ['ry_gate', 'ry_gate', 'rx_gate', 'rx_gate']]]\n",
    "mutate = AnsatzMutation(mutation_rate)\n",
    "mutate._do(offsprings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5085dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutate = AnsatzMutation(mutation_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "867b0710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmutate\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffsprings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mAnsatzMutation._do\u001b[39m\u001b[34m(self, offspring)\u001b[39m\n\u001b[32m     74\u001b[39m         mutated_offspring.append(mutated_individual)\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(mutated_offspring))\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m offspring_a, offspring_b = mutated_offspring\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m offspring_a, offspring_b\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "mutate._do(offsprings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".experiments (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
