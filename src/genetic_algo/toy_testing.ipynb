{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59442a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ansatz_simulation_class import AnsatzSimulation\n",
    "from genetic_quantum import QuanvLayer, QuantumModel, train_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from patch_making import PatchExtraction, Quanv_2d\n",
    "from torch import tensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2caf39e",
   "metadata": {},
   "source": [
    "### Instantiating genetic ansatz model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "609bea41",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "QuanvLayer.__init__() missing 1 required positional argument: 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m input_size = \u001b[32m28\u001b[39m\n\u001b[32m      5\u001b[39m toy_chromosome = [[\u001b[33m'\u001b[39m\u001b[33mctrl_0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrgt_0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mctrl_1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrgt_1\u001b[39m\u001b[33m'\u001b[39m], [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mctrl_0\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrgt_0\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m], [\u001b[33m'\u001b[39m\u001b[33mrz_gate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpauli_y\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrx_gate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mphase\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m quanv = \u001b[43mQuanvLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_qubits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoy_chromosome\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2d\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m toy_qhcnn = QuantumModel(n_qubits, num_classes, patch_size, input_size, toy_chromosome)\n\u001b[32m      8\u001b[39m toy_qhcnn\n",
      "\u001b[31mTypeError\u001b[39m: QuanvLayer.__init__() missing 1 required positional argument: 'parameters'"
     ]
    }
   ],
   "source": [
    "n_qubits = 4\n",
    "patch_size = 2\n",
    "num_classes = 2\n",
    "input_size = 28\n",
    "toy_chromosome = [['ctrl_0', 'trgt_0', 'ctrl_1', 'trgt_1'], [None, 'ctrl_0', 'trgt_0', None], ['rz_gate', 'pauli_y', 'rx_gate', 'phase']]\n",
    "quanv = QuanvLayer(n_qubits, patch_size, toy_chromosome, mode='2d')\n",
    "toy_qhcnn = QuantumModel(n_qubits, num_classes, patch_size, input_size, toy_chromosome)\n",
    "toy_qhcnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee926d7",
   "metadata": {},
   "source": [
    "### Getting data and sampling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    PatchExtraction(patch_size)])\n",
    "mnist_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9208afbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9a0fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11791"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_classes = [4, 9]\n",
    "reduced_mnist = [mnist_dataset.__getitem__(index) for index in range(mnist_dataset.__len__()) if mnist_dataset.__getitem__(index)[1] in selected_classes]\n",
    "len(reduced_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6c7305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9098, 0.9922],\n",
       "         [0.8235, 0.9882, 0.6588, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9882],\n",
       "         [0.7176, 0.0000, 0.3608, 0.9882],\n",
       "         [0.0824, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.9922, 0.6902, 0.0000, 0.0314],\n",
       "         [0.9608, 0.5059, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0863, 0.9882, 0.0863],\n",
       "         [0.7725, 0.9922, 0.9843, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.9216, 0.8510, 0.1647, 0.7529],\n",
       "         [0.5608, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9922, 0.0824, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9922],\n",
       "         [0.0824, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.0000, 0.0824, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.3765],\n",
       "         [0.7412, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5765, 0.1647],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3412, 0.9882, 0.7412],\n",
       "         [0.9882, 0.9922, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3765, 0.9882],\n",
       "         [0.0549, 0.0000, 0.9882, 0.8824],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.4941],\n",
       "         [0.9686, 0.0353, 0.0000, 0.3059],\n",
       "         [0.9922, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9882, 0.1176, 0.4667],\n",
       "         [0.9451, 0.9882, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.2157],\n",
       "         [0.9922, 0.5412, 0.0941, 0.9882],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2784, 0.9882, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.2784, 0.9882],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1765, 0.9922, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9882],\n",
       "         [0.1647, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0549, 0.9882, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2157, 0.8235, 0.9922, 0.3412],\n",
       "         [0.2157, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.2235, 0.9882, 0.2549],\n",
       "         [0.0471, 0.9882, 0.4549, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.5176, 0.9882],\n",
       "         [0.0549, 0.0000, 0.8431, 0.9882],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0627],\n",
       "         [0.9882, 0.0000, 0.0000, 0.7882],\n",
       "         [0.9882, 0.0431, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0627, 0.9882, 0.9882],\n",
       "         [0.9882, 0.8902, 0.9059, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.0000],\n",
       "         [0.4275, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9922, 0.0824, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9922],\n",
       "         [0.0824, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.8549, 0.2196, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0549],\n",
       "         [0.9882, 0.0431, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5804, 0.9922, 0.4431, 0.5804],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0157, 0.9490, 0.7451, 0.0196],\n",
       "         [0.7137, 0.9922, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.9922, 0.5725],\n",
       "         [0.0000, 0.0000, 0.9882, 0.3098],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.9098],\n",
       "         [0.6902, 0.0000, 0.1412, 0.9882],\n",
       "         [0.6627, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9059, 0.9922, 0.9882],\n",
       "         [0.8863, 0.9882, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.2431, 0.9922],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9882, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.4157, 0.9882],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.9882, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.7216],\n",
       "         [0.6667, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000]]),\n",
       " 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataset.__getitem__(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d515ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_one = 0\n",
    "class_two = 0\n",
    "binary_dataset = []\n",
    "\n",
    "for image in reduced_mnist:\n",
    "    if image[1] == 4 and class_one < 50:\n",
    "        binary_dataset.append(image)\n",
    "        class_one +=1 \n",
    "    elif image[1] == 9 and class_two < 50:\n",
    "        binary_dataset.append(image)\n",
    "        class_two += 1\n",
    "        \n",
    "    if class_one == 50 and class_two == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673e4fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd9477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_images, mnist_labels = zip(*binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "323a9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_mnist = torch.stack(mnist_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271dac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 196, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9be3c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_labels = [label%2 for label in mnist_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9bdc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_labels = tensor(mnist_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17639274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b0aa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 196, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_mnist.squeeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2725fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing through quanvolution layer...\n",
      "Image quantum processing time: 9.498604000080377\n",
      "Quanvolution processing time: 9.578680300153792\n",
      "Classical layers processing time: 0.03716449998319149\n"
     ]
    }
   ],
   "source": [
    "output = toy_qhcnn.forward(tensor_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d83385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6441, -0.7448],\n",
       "        [-0.6050, -0.7899],\n",
       "        [-0.6508, -0.7374],\n",
       "        [-0.6259, -0.7653],\n",
       "        [-0.6629, -0.7243],\n",
       "        [-0.6639, -0.7233],\n",
       "        [-0.6302, -0.7604],\n",
       "        [-0.6440, -0.7449],\n",
       "        [-0.6436, -0.7453],\n",
       "        [-0.6077, -0.7865],\n",
       "        [-0.6893, -0.6970],\n",
       "        [-0.6269, -0.7641],\n",
       "        [-0.6145, -0.7785],\n",
       "        [-0.6214, -0.7705],\n",
       "        [-0.6537, -0.7343],\n",
       "        [-0.6602, -0.7272],\n",
       "        [-0.6450, -0.7437],\n",
       "        [-0.6446, -0.7442],\n",
       "        [-0.6548, -0.7330],\n",
       "        [-0.6295, -0.7612],\n",
       "        [-0.6319, -0.7584],\n",
       "        [-0.6866, -0.6997],\n",
       "        [-0.6434, -0.7455],\n",
       "        [-0.5933, -0.8041],\n",
       "        [-0.6237, -0.7677],\n",
       "        [-0.6466, -0.7420],\n",
       "        [-0.6499, -0.7383],\n",
       "        [-0.6181, -0.7743],\n",
       "        [-0.6484, -0.7400],\n",
       "        [-0.6584, -0.7292],\n",
       "        [-0.6630, -0.7242],\n",
       "        [-0.6396, -0.7497],\n",
       "        [-0.6162, -0.7766],\n",
       "        [-0.5990, -0.7971],\n",
       "        [-0.6222, -0.7695],\n",
       "        [-0.6346, -0.7554],\n",
       "        [-0.6507, -0.7375],\n",
       "        [-0.5984, -0.7979],\n",
       "        [-0.6102, -0.7837],\n",
       "        [-0.6286, -0.7622],\n",
       "        [-0.6128, -0.7805],\n",
       "        [-0.5999, -0.7960],\n",
       "        [-0.6534, -0.7346],\n",
       "        [-0.6372, -0.7524],\n",
       "        [-0.6517, -0.7364],\n",
       "        [-0.6271, -0.7638],\n",
       "        [-0.6191, -0.7731],\n",
       "        [-0.6373, -0.7524],\n",
       "        [-0.6495, -0.7388],\n",
       "        [-0.6620, -0.7253],\n",
       "        [-0.6560, -0.7317],\n",
       "        [-0.6647, -0.7224],\n",
       "        [-0.6295, -0.7611],\n",
       "        [-0.6623, -0.7250],\n",
       "        [-0.5928, -0.8047],\n",
       "        [-0.6226, -0.7690],\n",
       "        [-0.6102, -0.7836],\n",
       "        [-0.6466, -0.7420],\n",
       "        [-0.6140, -0.7791],\n",
       "        [-0.6473, -0.7411],\n",
       "        [-0.6252, -0.7661],\n",
       "        [-0.6426, -0.7464],\n",
       "        [-0.6304, -0.7601],\n",
       "        [-0.6224, -0.7693],\n",
       "        [-0.6462, -0.7424],\n",
       "        [-0.6457, -0.7429],\n",
       "        [-0.6348, -0.7551],\n",
       "        [-0.6732, -0.7135],\n",
       "        [-0.6230, -0.7686],\n",
       "        [-0.6793, -0.7072],\n",
       "        [-0.6179, -0.7746],\n",
       "        [-0.6315, -0.7588],\n",
       "        [-0.6318, -0.7585],\n",
       "        [-0.6766, -0.7100],\n",
       "        [-0.6077, -0.7866],\n",
       "        [-0.6433, -0.7456],\n",
       "        [-0.6446, -0.7442],\n",
       "        [-0.6355, -0.7543],\n",
       "        [-0.6568, -0.7308],\n",
       "        [-0.6686, -0.7183],\n",
       "        [-0.6161, -0.7766],\n",
       "        [-0.5949, -0.8021],\n",
       "        [-0.6285, -0.7622],\n",
       "        [-0.6854, -0.7010],\n",
       "        [-0.6729, -0.7138],\n",
       "        [-0.6626, -0.7247],\n",
       "        [-0.6083, -0.7859],\n",
       "        [-0.6383, -0.7512],\n",
       "        [-0.5930, -0.8045],\n",
       "        [-0.6373, -0.7523],\n",
       "        [-0.6358, -0.7539],\n",
       "        [-0.6333, -0.7568],\n",
       "        [-0.6557, -0.7321],\n",
       "        [-0.6139, -0.7792],\n",
       "        [-0.6271, -0.7639],\n",
       "        [-0.6827, -0.7037],\n",
       "        [-0.6369, -0.7528],\n",
       "        [-0.6668, -0.7202],\n",
       "        [-0.6644, -0.7228],\n",
       "        [-0.6578, -0.7298]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c90f06",
   "metadata": {},
   "source": [
    "### Training my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def43503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampled_cv_dataset import SampledDataset4Training\n",
    "\n",
    "quantum_processing = transforms.Compose([Quanv_2d(n_qubits, toy_chromosome)])\n",
    "training_zeros_ones = SampledDataset4Training(binary_dataset, transform=quantum_processing)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "training_loader = DataLoader(training_zeros_ones, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5cfd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_zeros_ones.__getitem__(0)['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f348f248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([196, 4]) 4\n",
      "1 torch.Size([196, 4]) 9\n",
      "2 torch.Size([196, 4]) 4\n",
      "3 torch.Size([196, 4]) 9\n",
      "4 torch.Size([196, 4]) 4\n",
      "5 torch.Size([196, 4]) 9\n",
      "6 torch.Size([196, 4]) 4\n",
      "7 torch.Size([196, 4]) 9\n",
      "8 torch.Size([196, 4]) 9\n",
      "9 torch.Size([196, 4]) 9\n",
      "10 torch.Size([196, 4]) 9\n",
      "11 torch.Size([196, 4]) 4\n",
      "12 torch.Size([196, 4]) 9\n",
      "13 torch.Size([196, 4]) 9\n",
      "14 torch.Size([196, 4]) 4\n",
      "15 torch.Size([196, 4]) 4\n",
      "16 torch.Size([196, 4]) 4\n",
      "17 torch.Size([196, 4]) 4\n",
      "18 torch.Size([196, 4]) 9\n",
      "19 torch.Size([196, 4]) 9\n",
      "20 torch.Size([196, 4]) 4\n",
      "21 torch.Size([196, 4]) 4\n",
      "22 torch.Size([196, 4]) 9\n",
      "23 torch.Size([196, 4]) 4\n",
      "24 torch.Size([196, 4]) 9\n",
      "25 torch.Size([196, 4]) 4\n",
      "26 torch.Size([196, 4]) 4\n",
      "27 torch.Size([196, 4]) 9\n",
      "28 torch.Size([196, 4]) 4\n",
      "29 torch.Size([196, 4]) 4\n",
      "30 torch.Size([196, 4]) 4\n",
      "31 torch.Size([196, 4]) 9\n",
      "32 torch.Size([196, 4]) 9\n",
      "33 torch.Size([196, 4]) 9\n",
      "34 torch.Size([196, 4]) 4\n",
      "35 torch.Size([196, 4]) 4\n",
      "36 torch.Size([196, 4]) 4\n",
      "37 torch.Size([196, 4]) 9\n",
      "38 torch.Size([196, 4]) 9\n",
      "39 torch.Size([196, 4]) 9\n",
      "40 torch.Size([196, 4]) 9\n",
      "41 torch.Size([196, 4]) 9\n",
      "42 torch.Size([196, 4]) 4\n",
      "43 torch.Size([196, 4]) 9\n",
      "44 torch.Size([196, 4]) 4\n",
      "45 torch.Size([196, 4]) 4\n",
      "46 torch.Size([196, 4]) 9\n",
      "47 torch.Size([196, 4]) 9\n",
      "48 torch.Size([196, 4]) 4\n",
      "49 torch.Size([196, 4]) 9\n",
      "50 torch.Size([196, 4]) 4\n",
      "51 torch.Size([196, 4]) 9\n",
      "52 torch.Size([196, 4]) 9\n",
      "53 torch.Size([196, 4]) 4\n",
      "54 torch.Size([196, 4]) 4\n",
      "55 torch.Size([196, 4]) 4\n",
      "56 torch.Size([196, 4]) 9\n",
      "57 torch.Size([196, 4]) 9\n",
      "58 torch.Size([196, 4]) 9\n",
      "59 torch.Size([196, 4]) 4\n",
      "60 torch.Size([196, 4]) 4\n",
      "61 torch.Size([196, 4]) 4\n",
      "62 torch.Size([196, 4]) 4\n",
      "63 torch.Size([196, 4]) 9\n",
      "64 torch.Size([196, 4]) 9\n",
      "65 torch.Size([196, 4]) 4\n",
      "66 torch.Size([196, 4]) 9\n",
      "67 torch.Size([196, 4]) 9\n",
      "68 torch.Size([196, 4]) 4\n",
      "69 torch.Size([196, 4]) 9\n",
      "70 torch.Size([196, 4]) 4\n",
      "71 torch.Size([196, 4]) 4\n",
      "72 torch.Size([196, 4]) 4\n",
      "73 torch.Size([196, 4]) 9\n",
      "74 torch.Size([196, 4]) 9\n",
      "75 torch.Size([196, 4]) 9\n",
      "76 torch.Size([196, 4]) 4\n",
      "77 torch.Size([196, 4]) 9\n",
      "78 torch.Size([196, 4]) 4\n",
      "79 torch.Size([196, 4]) 9\n",
      "80 torch.Size([196, 4]) 4\n",
      "81 torch.Size([196, 4]) 4\n",
      "82 torch.Size([196, 4]) 4\n",
      "83 torch.Size([196, 4]) 9\n",
      "84 torch.Size([196, 4]) 4\n",
      "85 torch.Size([196, 4]) 4\n",
      "86 torch.Size([196, 4]) 9\n",
      "87 torch.Size([196, 4]) 9\n",
      "88 torch.Size([196, 4]) 4\n",
      "89 torch.Size([196, 4]) 9\n",
      "90 torch.Size([196, 4]) 4\n",
      "91 torch.Size([196, 4]) 4\n",
      "92 torch.Size([196, 4]) 4\n",
      "93 torch.Size([196, 4]) 9\n",
      "94 torch.Size([196, 4]) 9\n",
      "95 torch.Size([196, 4]) 9\n",
      "96 torch.Size([196, 4]) 9\n",
      "97 torch.Size([196, 4]) 9\n",
      "98 torch.Size([196, 4]) 4\n",
      "99 torch.Size([196, 4]) 4\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(training_zeros_ones):\n",
    "    print(i, sample['image'].shape, sample['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "970ae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(toy_qhcnn.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#loss = loss_fn(output, mnist_labels)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bfbe662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalComponent(nn.Module):\n",
    "    def __init__(self, num_classes, input_size):\n",
    "        super().__init__()\n",
    "        feature_size = input_size ** 2\n",
    "        self.fc1 = nn.Linear(feature_size, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10146a35",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m simple_fc = ClassicalComponent(num_classes, input_size)\n\u001b[32m      2\u001b[39m num_epochs = \u001b[32m4\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimple_fc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, num_epochs)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[32m      8\u001b[39m     optimizer.zero_grad()  \u001b[38;5;66;03m# Zero out previous gradients\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     loss = loss_fn(outputs, labels)  \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[32m     11\u001b[39m     loss.backward()  \u001b[38;5;66;03m# Backpropagate to calculate gradients\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\.genetic_circuits\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\.genetic_circuits\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mClassicalComponent.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     x = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m(start_dim=\u001b[32m1\u001b[39m)\n\u001b[32m     10\u001b[39m     x = F.relu(\u001b[38;5;28mself\u001b[39m.fc1(x))\n\u001b[32m     11\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fc2(x)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "simple_fc = ClassicalComponent(num_classes, input_size)\n",
    "num_epochs = 4\n",
    "train_model(simple_fc, training_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01040e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad()  # Zero out previous gradients\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)  # Calculate loss\n",
    "            loss.backward()  # Backpropagate to calculate gradients\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 4 == 0:  # Print every 10 batches\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e041461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/25 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing through quanvolution layer...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoy_qhcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\genetic_quantum.py:166\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, device, num_epochs, log_interval)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, labels) \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m#images = images.to(device)\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m#labels = labels.squeeze().to(device)\u001b[39;00m\n\u001b[32m    165\u001b[39m     optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m    167\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m    168\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\.genetic_circuits\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\.genetic_circuits\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\genetic_quantum.py:139\u001b[39m, in \u001b[36mQuantumModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPassing through quanvolution layer...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    138\u001b[39m start_time = time.perf_counter()\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquanv_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m       \n\u001b[32m    140\u001b[39m end_time = time.perf_counter()\n\u001b[32m    141\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mQuanvolution processing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)  \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\genetic_quantum.py:92\u001b[39m, in \u001b[36mQuanvLayer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33m2d\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquanv_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mhorizontal\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quanv1d_horizontal(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\genetic_quantum.py:28\u001b[39m, in \u001b[36mQuanvLayer.quanv_2d\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquanv_2d\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m#print(type(x))\u001b[39;00m\n\u001b[32m     27\u001b[39m     start_time = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     outputs = [[\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimulate_circuit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchromosome\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m patch \u001b[38;5;129;01min\u001b[39;00m patches] \u001b[38;5;28;01mfor\u001b[39;00m patches \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[32m     29\u001b[39m     end_time = time.perf_counter()\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mImage quantum processing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\ansatz_simulation_class.py:162\u001b[39m, in \u001b[36mAnsatzSimulation.simulate_circuit\u001b[39m\u001b[34m(self, input, embedding_type, ansatz_chromosome)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimulate_circuit\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor, embedding_type: \u001b[38;5;28mstr\u001b[39m, ansatz_chromosome: \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    160\u001b[39m     layer_count = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     state_vector = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muniformAngleEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_type\u001b[49m\u001b[43m)\u001b[49m.view((\u001b[32m2\u001b[39m,)*\u001b[38;5;28mself\u001b[39m.n_qubits)\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m ansatz_chromosome:\n\u001b[32m    165\u001b[39m         \u001b[38;5;66;03m#print(f'Starting simulation at layer #{layer_count}')\u001b[39;00m\n\u001b[32m    166\u001b[39m         qubit_count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\ansatz_simulation_class.py:116\u001b[39m, in \u001b[36mAnsatzSimulation.uniformAngleEmbedding\u001b[39m\u001b[34m(self, patch_vector, rotation_gate)\u001b[39m\n\u001b[32m    114\u001b[39m eye_tensor[\u001b[32m0\u001b[39m] = \u001b[32m1.0\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rotation_gate == \u001b[33m'\u001b[39m\u001b[33mrx\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrotation_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrx_gate\u001b[49m\u001b[43m)\u001b[49m @ eye_tensor\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m rotation_gate == \u001b[33m'\u001b[39m\u001b[33mry\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rotation_states(patch_vector, \u001b[38;5;28mself\u001b[39m.ry_gate) @ eye_tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\ansatz_simulation_class.py:72\u001b[39m, in \u001b[36mAnsatzSimulation.rotation_states\u001b[39m\u001b[34m(self, patch_vector, rotation_gate)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrotation_states\u001b[39m(\u001b[38;5;28mself\u001b[39m, patch_vector, rotation_gate):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     state_vector = \u001b[43mrotation_gate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch_vector\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(patch_vector) - \u001b[32m1\u001b[39m):\n\u001b[32m     74\u001b[39m         state_vector = torch.kron(state_vector, rotation_gate(patch_vector[index+\u001b[32m1\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\ansatz_simulation_class.py:53\u001b[39m, in \u001b[36mAnsatzSimulation.rx_gate\u001b[39m\u001b[34m(self, theta)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrx_gate\u001b[39m(\u001b[38;5;28mself\u001b[39m, theta = math.pi/\u001b[32m2\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor([[math.cos(\u001b[43mtheta\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m2\u001b[39;49m), -\u001b[32m1\u001b[39mj*math.sin(theta/\u001b[32m2\u001b[39m)],\n\u001b[32m     54\u001b[39m                         [-\u001b[32m1\u001b[39mj*math.sin(theta/\u001b[32m2\u001b[39m), math.cos(theta/\u001b[32m2\u001b[39m)]], dtype=torch.complex64)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "train_model(toy_qhcnn, training_loader, loss_fn, optimizer, device, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f07947b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0bef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bc791",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tensor or list of tensors expected, got <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m dataiter = \u001b[38;5;28miter\u001b[39m(training_loader)\n\u001b[32m     12\u001b[39m images, labels = \u001b[38;5;28mnext\u001b[39m(dataiter)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m img_grid = \u001b[43mmake_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m matplotlib_imshow(img_grid, one_channel=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\.genetic_circuits\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\speak\\Genetic-Algorithm-based-Optimization-for-Quantum-Circuit-Synthesis\\src\\genetic_algo\\.genetic_circuits\\Lib\\site-packages\\torchvision\\utils.py:64\u001b[39m, in \u001b[36mmake_grid\u001b[39m\u001b[34m(tensor, nrow, padding, normalize, value_range, scale_each, pad_value)\u001b[39m\n\u001b[32m     62\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtensor or list of tensors expected, got a list containing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(t)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtensor or list of tensors expected, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# if list of tensors, convert to a 4D mini-batch Tensor\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[31mTypeError\u001b[39m: tensor or list of tensors expected, got <class 'str'>"
     ]
    }
   ],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img_grid = make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdd567",
   "metadata": {},
   "source": [
    "### Testing tensor dimensions and quantum convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704233ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import image\n",
    "from torch import tensor\n",
    "\n",
    "input_size = 4\n",
    "dummy_input = torch.zeros(input_size, input_size, 2).numpy()\n",
    "patched_images = [image.extract_patches_2d(img, (patch_size, patch_size)) for img in dummy_input]\n",
    "#dummy_output = quanv.forward(dummy_input)\n",
    "\n",
    "tensor(patched_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f186a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import image\n",
    "from torch import tensor\n",
    "\n",
    "input_size = 28\n",
    "\n",
    "shape = (input_size, input_size)\n",
    "dummy_input = np.zeros(shape, dtype=float)\n",
    "patched_images = image.extract_patches_2d(dummy_input, (patch_size, patch_size)) \n",
    "#dummy_output = quanv.forward(dummy_input)\n",
    "n_patches, patch_h, patch_w = tensor(patched_images).shape\n",
    "patched_images = tensor(patched_images).contiguous().view(n_patches, patch_h*patch_w)\n",
    "image._extract_patches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f9a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([729, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patched_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9251b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "myAnsatz = AnsatzSimulation(n_qubits)\n",
    "outputs = [myAnsatz.simulate_circuit(patch, 'rx', toy_chromosome) for patch in patched_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e60ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1458, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(outputs).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".genetic_circuits (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
